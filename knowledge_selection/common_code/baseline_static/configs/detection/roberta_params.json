{
    "dataset_args": {
      "history_max_utterances": 1000000,
      "history_max_tokens": 128,
      "knowledge_max_tokens": 128,
      "selection_type" : "body"
    },
    
  
    "task": "detection",
    "model_name_or_path": "roberta-base",
  
    "per_gpu_train_batch_size": 32,
    "per_gpu_eval_batch_size": 64,
    "gradient_accumulation_steps": 1,
    "max_candidates_per_forward_eval": 256,
    
    "learning_rate": 3e-6,
    "adam_epsilon": 1e-8,
    "max_grad_norm": 5.0,
  
    "num_train_epochs": 20,
    "warmup_steps": 0,
  
    "fp16": "",
  
    "seed": 42
  }
  